import os
import hashlib
from datetime import datetime
import requests
from bs4 import BeautifulSoup
import telegram
import time
import schedule
import json

# Configura√ß√£o
TELEGRAM_TOKEN = "7802497378:AAF4KQZqPCuCYPp2R-QWse2SOtWl8iCiE3k"
CHAT_ID = "891690046"
SITES_IMOBILIARIAS = [
    "https://www.criativaimoveis.com.br/imovel/alugar",
    "https://sinuelo.net/",
    "https://sinuelo.net/busca?finalidade=Aluguel&tipo=Apartamento%2CCasa&cidade=Novo+Hamburgo%2CNOVO+HAMBURGO",
    "https://www.houseimoveis.com.br/imoveis/aluguel/novo-hamburgo/-/-/apartamento+apartamento+casa+casa+casa-em-condominio+casa-em-condominio?filtros&min=120&max=15000&ordem=desc-valor&pagination=1"
]

# Inicializar bot do Telegram
bot = telegram.Bot(token=TELEGRAM_TOKEN)

# Arquivo para salvar hashes das p√°ginas monitoradas
HASHES_ARQUIVO = 'paginas_hashes.json'
LOGS_ARQUIVO = 'notificacoes.txt'  # Definindo a vari√°vel LOGS_ARQUIVO aqui

def main():
    print("Bot de monitoramento de im√≥veis iniciado!")

    # Enviar notifica√ß√£o de inicializa√ß√£o
    enviar_notificacao("üè† *Bot de Monitoramento de Im√≥veis Iniciado!*\n\nO bot est√° monitorando os seguintes sites:\n" +
                       "\n".join(f"- {site}" for site in SITES_IMOBILIARIAS))

# Fun√ß√£o para enviar notifica√ß√µes via Telegram
def enviar_notificacao(mensagem):
    try:
        # Salvar em arquivo para backup
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        with open(LOGS_ARQUIVO, 'a', encoding='utf-8') as f:
            f.write(f"[{timestamp}] {mensagem}\n\n")

        # Enviar para o Telegram
        bot.send_message(
            chat_id=CHAT_ID,
            text=mensagem,
            parse_mode="Markdown"  # Opcional: permite formata√ß√£o b√°sica
        )
        print(f"Notifica√ß√£o enviada para o Telegram: {mensagem[:50]}...")

    except Exception as e:
        print(f"Erro ao enviar notifica√ß√£o para o Telegram: {str(e)}")
        print("A mensagem foi salva apenas no arquivo de logs.")

# Carregar hashes das p√°ginas anteriores
def carregar_hashes():
    if os.path.exists(HASHES_ARQUIVO):
        with open(HASHES_ARQUIVO, 'r') as f:
            return json.load(f)
    return {}

# Salvar hashes atuais
def salvar_hashes(hashes):
    with open(HASHES_ARQUIVO, 'w') as f:
        json.dump(hashes, f)

# Fun√ß√£o para limpar o HTML removendo partes n√£o relevantes
def limpar_html(html):
    soup = BeautifulSoup(html, 'html.parser')

    # Remover scripts, estilos e coment√°rios
    for tag in soup(['script', 'style', 'meta', 'link', 'noscript']):
        tag.decompose()

    # Remover coment√°rios HTML
    for comment in soup.find_all(string=lambda text: isinstance(text, str) and '<!--' in text):
        comment.extract()

    return str(soup)

# Extrair se√ß√µes potenciais de listagens
def extrair_secoes_listagem(html):
    soup = BeautifulSoup(html, 'html.parser')

    # Procurar se√ß√µes que provavelmente s√£o listagens de im√≥veis
    # Estrat√©gia 1: Procurar por cont√™ineres com v√°rios elementos similares
    secoes = []

    # Procurar padr√µes comuns em sites imobili√°rios
    padrao_classes = ['listing', 'results', 'properties', 'imoveis', 'cards', 'grid', 'lista']
    for classe in padrao_classes:
        containers = soup.select(f"div[class*='{classe}'], ul[class*='{classe}'], section[class*='{classe}']")
        secoes.extend(containers)

    # Se nada for encontrado, procurar divs que cont√™m m√∫ltiplos elementos com estrutura similar
    if not secoes:
        candidatos = soup.select('div, section, ul')
        for candidato in candidatos:
            # Verificar se tem v√°rios filhos similares (potencial listagem)
            filhos = candidato.find_all(['article', 'div', 'li'], recursive=False)
            if len(filhos) >= 3:  # Pelo menos 3 itens similares
                secoes.append(candidato)

    # Se ainda n√£o encontrou nada, procurar por artigos ou cards
    if not secoes:
        secoes = soup.select('article, div.card, div[class*="card"], li[class*="item"]')

    return secoes

# Fun√ß√£o principal para verificar mudan√ßas nas se√ß√µes de listagens
def verificar_mudancas():
    hashes_anteriores = carregar_hashes()
    hashes_atuais = {}
    mudancas_detectadas = False

    for site in SITES_IMOBILIARIAS:
        print(f"Verificando: {site}")

        try:
            # Fazer requisi√ß√£o HTTP com cabe√ßalhos de navegador
            headers = {
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
                "Accept": "text/html,application/xhtml+xml,application/xml",
                "Accept-Language": "pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7"
            }
            response = requests.get(site, headers=headers, timeout=30)

            if response.status_code == 200:
                # Limpar o HTML
                html_limpo = limpar_html(response.text)

                # Extrair se√ß√µes que parecem ser listagens
                secoes = extrair_secoes_listagem(html_limpo)

                # Se n√£o encontrou se√ß√µes espec√≠ficas, usar a p√°gina toda
                if not secoes:
                    print(f"Nenhuma se√ß√£o de listagem identificada em {site}. Usando p√°gina completa.")
                    secoes = [BeautifulSoup(html_limpo, 'html.parser')]

                print(f"Encontradas {len(secoes)} poss√≠veis se√ß√µes de listagem em {site}")

                # Para cada se√ß√£o, calcular um hash
                hashes_secoes = []
                for i, secao in enumerate(secoes):
                    # Pegar apenas o texto e links, ignorando formata√ß√£o
                    conteudo = []
                    for elem in secao.find_all(['a', 'h1', 'h2', 'h3', 'h4', 'p', 'span']):
                        if elem.name == 'a' and elem.get('href'):
                            conteudo.append(f"{elem.text.strip()}:{elem.get('href')}")
                        else:
                            conteudo.append(elem.text.strip())

                    # Filtrar strings vazias
                    conteudo = [c for c in conteudo if c]

                    if conteudo:
                        # Calcular hash do conte√∫do
                        conteudo_str = '|'.join(conteudo)
                        hash_secao = hashlib.md5(conteudo_str.encode('utf-8')).hexdigest()
                        hashes_secoes.append(hash_secao)

                # Verificar se h√° mudan√ßas
                site_key = site.split('/')[2]  # Ex: www.imobiliaria1.com.br

                if site_key in hashes_anteriores:
                    # Comparar hashes anteriores com atuais
                    hashes_antigos = set(hashes_anteriores[site_key])
                    hashes_novos = set(hashes_secoes)

                    # Verificar se h√° novos hashes (novas se√ß√µes ou se√ß√µes alteradas)
                    novos = hashes_novos - hashes_antigos

                    if novos:
                        mudancas_detectadas = True
                        num_novos = len(novos)
                        mensagem = f"üè† NOVOS IM√ìVEIS DETECTADOS!\n\n"
                        mensagem += f"Detectei mudan√ßas em {num_novos} se√ß√£o(√µes) em:\n"
                        mensagem += f"{site_key} - {site}\n\n"
                        mensagem += "Acesse o site para ver os novos im√≥veis!"
                        enviar_notificacao(mensagem)

                # Armazenar hashes atuais para pr√≥xima verifica√ß√£o
                hashes_atuais[site_key] = hashes_secoes

            else:
                print(f"Erro ao acessar {site}: Status code {response.status_code}")

        except Exception as e:
            print(f"Erro ao processar {site}: {str(e)}")

    # Salvar os hashes atuais
    salvar_hashes(hashes_atuais)

    return mudancas_detectadas

# Loop principal
def main():
    print("Bot de monitoramento de im√≥veis iniciado!")
    print("Este bot detecta mudan√ßas em listagens de im√≥veis sem precisar de seletores CSS espec√≠ficos.")

    # Se for a primeira execu√ß√£o, apenas salvar os hashes iniciais
    if not os.path.exists(HASHES_ARQUIVO):
        print("Primeira execu√ß√£o: salvando estado inicial dos sites...")
        verificar_mudancas()
        print("Estado inicial salvo. O bot detectar√° mudan√ßas a partir da pr√≥xima verifica√ß√£o.")

    intervalo_minutos = 30

    while True:
        print(f"\nVerificando sites em {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}...")
        verificar_mudancas()
        print(f"Pr√≥xima verifica√ß√£o em {intervalo_minutos} minutos.")
        time.sleep(intervalo_minutos * 60)  # Converter para segundos

if __name__ == "__main__":
    main()