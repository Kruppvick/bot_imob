import os
import hashlib
from datetime import datetime
import requests
from bs4 import BeautifulSoup
import telegram
import time
import schedule
import json
import sys

# Configura√ß√£o
TELEGRAM_TOKEN = os.environ.get('TELEGRAM_TOKEN')
CHAT_ID = os.environ.get('CHAT_ID')

# Sites para monitorar - tamb√©m via vari√°vel de ambiente
sites_env = os.environ.get('SITES_IMOBILIARIAS', '')
SITES_IMOBILIARIAS = [site.strip() for site in sites_env.split(',') if site.strip()]

# Se n√£o houver sites definidos no ambiente, use esta lista padr√£o
if not SITES_IMOBILIARIAS:
    SITES_IMOBILIARIAS = [
        # Adicione suas URLs aqui como fallback
    ]

# Inicializar bot do Telegram
bot = telegram.Bot(token=TELEGRAM_TOKEN) if TELEGRAM_TOKEN else None

# Arquivo para salvar hashes das p√°ginas monitoradas
HASHES_ARQUIVO = 'paginas_hashes.json'
LOGS_ARQUIVO = 'notificacoes.txt'  # Definindo a vari√°vel LOGS_ARQUIVO aqui

def salvar_hashes(hashes):
    print(f"Salvando hashes em: {os.path.abspath(HASHES_ARQUIVO)}")
    print(f"Conte√∫do dos hashes: {json.dumps(hashes)[:200]}...")  # Mostrar in√≠cio do conte√∫do
    
    with open(HASHES_ARQUIVO, 'w', encoding='utf-8') as f:
        json.dump(hashes, f)
    
    print(f"Arquivo salvo. Tamanho: {os.path.getsize(HASHES_ARQUIVO)} bytes")

# Configurar caminho para arquivos com base no diret√≥rio atual
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
HASHES_ARQUIVO = os.path.join(BASE_DIR, 'paginas_hashes.json')
LOGS_ARQUIVO = os.path.join(BASE_DIR, 'notificacoes.txt')

print(f"Diret√≥rio base: {BASE_DIR}")
print(f"Arquivo de hashes: {HASHES_ARQUIVO}")

# Fun√ß√£o para enviar notifica√ß√£o
def enviar_notificacao(mensagem):
    # Salvar em arquivo
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    with open(LOGS_ARQUIVO, 'a', encoding='utf-8') as f:
        f.write(f"[{timestamp}] {mensagem}\n\n")

    # Enviar para o Telegram se configurado
    if bot:
        try:
            bot.send_message(
                chat_id=CHAT_ID,
                text=mensagem,
                parse_mode="Markdown"
            )
            print(f"Notifica√ß√£o enviada para o Telegram")
        except Exception as e:
            print(f"Erro ao enviar notifica√ß√£o para o Telegram: {str(e)}")
    else:
        print("Telegram n√£o configurado. Mensagem salva apenas no arquivo.")

    print(mensagem)

# Carregar hashes das p√°ginas anteriores
def carregar_hashes():
    if os.path.exists(HASHES_ARQUIVO):
        with open(HASHES_ARQUIVO, 'r') as f:
            return json.load(f)
    return {}

# Salvar hashes atuais
def salvar_hashes(hashes):
    with open(HASHES_ARQUIVO, 'w') as f:
        json.dump(hashes, f)

# Fun√ß√£o para limpar o HTML removendo partes n√£o relevantes
def limpar_html(html):
    soup = BeautifulSoup(html, 'html.parser')

    # Remover scripts, estilos e coment√°rios
    for tag in soup(['script', 'style', 'meta', 'link', 'noscript']):
        tag.decompose()

    # Remover coment√°rios HTML
    for comment in soup.find_all(string=lambda text: isinstance(text, str) and '<!--' in text):
        comment.extract()

    return str(soup)

# Extrair se√ß√µes potenciais de listagens
def extrair_secoes_listagem(html):
    soup = BeautifulSoup(html, 'html.parser')

    # Procurar se√ß√µes que provavelmente s√£o listagens de im√≥veis
    # Estrat√©gia 1: Procurar por cont√™ineres com v√°rios elementos similares
    secoes = []

    # Procurar padr√µes comuns em sites imobili√°rios
    padrao_classes = ['listing', 'results', 'properties', 'imoveis', 'cards', 'grid', 'lista']
    for classe in padrao_classes:
        containers = soup.select(f"div[class*='{classe}'], ul[class*='{classe}'], section[class*='{classe}']")
        secoes.extend(containers)

    # Se nada for encontrado, procurar divs que cont√™m m√∫ltiplos elementos com estrutura similar
    if not secoes:
        candidatos = soup.select('div, section, ul')
        for candidato in candidatos:
            # Verificar se tem v√°rios filhos similares (potencial listagem)
            filhos = candidato.find_all(['article', 'div', 'li'], recursive=False)
            if len(filhos) >= 3:  # Pelo menos 3 itens similares
                secoes.append(candidato)

    # Se ainda n√£o encontrou nada, procurar por artigos ou cards
    if not secoes:
        secoes = soup.select('article, div.card, div[class*="card"], li[class*="item"]')

    return secoes

# Fun√ß√£o principal para verificar mudan√ßas nas se√ß√µes de listagens
def verificar_mudancas():
    hashes_anteriores = carregar_hashes()
    hashes_atuais = {}
    mudancas_detectadas = False

    for site in SITES_IMOBILIARIAS:
        print(f"Verificando: {site}")

        try:
            # Fazer requisi√ß√£o HTTP com cabe√ßalhos de navegador
            headers = {
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
                "Accept": "text/html,application/xhtml+xml,application/xml",
                "Accept-Language": "pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7"
            }
            response = requests.get(site, headers=headers, timeout=30)

            if response.status_code == 200:
                # Limpar o HTML
                html_limpo = limpar_html(response.text)

                # Extrair se√ß√µes que parecem ser listagens
                secoes = extrair_secoes_listagem(html_limpo)

                # Se n√£o encontrou se√ß√µes espec√≠ficas, usar a p√°gina toda
                if not secoes:
                    print(f"Nenhuma se√ß√£o de listagem identificada em {site}. Usando p√°gina completa.")
                    secoes = [BeautifulSoup(html_limpo, 'html.parser')]

                print(f"Encontradas {len(secoes)} poss√≠veis se√ß√µes de listagem em {site}")

                # Para cada se√ß√£o, calcular um hash
                hashes_secoes = []
                for i, secao in enumerate(secoes):
                    # Pegar apenas o texto e links, ignorando formata√ß√£o
                    conteudo = []
                    for elem in secao.find_all(['a', 'h1', 'h2', 'h3', 'h4', 'p', 'span']):
                        if elem.name == 'a' and elem.get('href'):
                            conteudo.append(f"{elem.text.strip()}:{elem.get('href')}")
                        else:
                            conteudo.append(elem.text.strip())

                    # Filtrar strings vazias
                    conteudo = [c for c in conteudo if c]

                    if conteudo:
                        # Calcular hash do conte√∫do
                        conteudo_str = '|'.join(conteudo)
                        hash_secao = hashlib.md5(conteudo_str.encode('utf-8')).hexdigest()
                        hashes_secoes.append(hash_secao)

                # Verificar se h√° mudan√ßas
                site_key = site.split('/')[2]  # Ex: www.imobiliaria1.com.br

                if site_key in hashes_anteriores:
                    # Comparar hashes anteriores com atuais
                    hashes_antigos = set(hashes_anteriores[site_key])
                    hashes_novos = set(hashes_secoes)

                    # Verificar se h√° novos hashes (novas se√ß√µes ou se√ß√µes alteradas)
                    novos = hashes_novos - hashes_antigos

                    if novos:
                        mudancas_detectadas = True
                        num_novos = len(novos)
                        mensagem = f"üè† NOVOS IM√ìVEIS DETECTADOS!\n\n"
                        mensagem += f"Detectei mudan√ßas em {num_novos} se√ß√£o(√µes) em:\n"
                        mensagem += f"{site_key} - {site}\n\n"
                        mensagem += "Acesse o site para ver os novos im√≥veis!"
                        enviar_notificacao(mensagem)

                # Armazenar hashes atuais para pr√≥xima verifica√ß√£o
                hashes_atuais[site_key] = hashes_secoes

            else:
                print(f"Erro ao acessar {site}: Status code {response.status_code}")

        except Exception as e:
            print(f"Erro ao processar {site}: {str(e)}")

    # Salvar os hashes atuais
    salvar_hashes(hashes_atuais)

    return mudancas_detectadas

# 5. BLOCO PRINCIPAL DE EXECU√á√ÉO
if __name__ == "__main__":
    print(f"Bot de monitoramento iniciando verifica√ß√£o em {datetime.now()}")

    # Verificar configura√ß√µes
    if not TELEGRAM_TOKEN or not CHAT_ID:
        print("AVISO: Token do Telegram ou Chat ID n√£o configurados!")
        print("As notifica√ß√µes ser√£o salvas apenas em arquivo.")

    if not SITES_IMOBILIARIAS:
        print("ERRO: Nenhum site configurado para monitorar!")
        sys.exit(1)

    print(f"Monitorando {len(SITES_IMOBILIARIAS)} sites.")

    # Verificar se o arquivo de hashes j√° existe
    if not os.path.exists(HASHES_ARQUIVO):
        print(f"Arquivo de hashes n√£o encontrado. Criando arquivo inicial...")
        # Criar um arquivo inicial vazio
        with open(HASHES_ARQUIVO, 'w', encoding='utf-8') as f:
            json.dump({}, f)
        print(f"Arquivo de hashes inicial criado: {HASHES_ARQUIVO}")

    # No GitHub Actions, executamos apenas uma verifica√ß√£o por execu√ß√£o
    verificar_mudancas()

    print(f"Verifica√ß√£o conclu√≠da em {datetime.now()}")
